import cv2
import os
import numpy as np
import json
import logging

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
for h in logging.root.handlers[:]:
    logging.root.removeHandler(h)

# ìƒˆ í•¸ë“¤ëŸ¬ ë“±ë¡
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)

logging.debug("ğŸ”¥ ë¡œê·¸ ì¶œë ¥ í…ŒìŠ¤íŠ¸")


def normalize_keys(pose_dict):
    return {k.lower(): v for k, v in pose_dict.items()}

# MediaPipe ìŠ¤íƒ€ì¼ ê¸°ë³¸ ì—°ê²°ê´€ê³„ (ì¼ë°˜ì ì¸ 2D í¬ì¦ˆ ê¸°ì¤€)
POSE_CONNECTIONS = [
    ("left_shoulder", "right_shoulder"),
    ("left_shoulder", "left_elbow"),
    ("left_elbow", "left_wrist"),
    ("right_shoulder", "right_elbow"),
    ("right_elbow", "right_wrist"),
    ("left_shoulder", "left_hip"),
    ("right_shoulder", "right_hip"),
    ("left_hip", "right_hip"),
    ("left_hip", "left_knee"),
    ("left_knee", "left_ankle"),
    ("right_hip", "right_knee"),
    ("right_knee", "right_ankle"),
]

def to_centered_pixel(p, w, h, scale=0.3):
    cx = int(w / 2 + p['x'] * w * scale)
    cy = int(h / 2 + p['y'] * h * scale)
    return cx, cy


def draw_pose(frame, pose_dict, color, w, h):
    def to_px(p):
        return to_centered_pixel(p, w, h, scale=0.3)  # âœ… ì¤‘ì•™ ë°°ì¹˜ ì ìš©

    for joint1, joint2 in POSE_CONNECTIONS:
        if joint1 in pose_dict and joint2 in pose_dict:
            pt1 = to_px(pose_dict[joint1])
            pt2 = to_px(pose_dict[joint2])
            cv2.line(frame, pt1, pt2, color, 1)

    for joint in pose_dict:
        pt = to_px(pose_dict[joint])
        cv2.circle(frame, pt, 2, color, -1)



def draw_skeletons_without_video(user_pose_dict, ref_pose_dict, output_path, w=720, h=1280, fps=30):
    cv2.namedWindow('Pose Only', cv2.WINDOW_NORMAL)
    w, h = 720, 1280  # ì›í•˜ëŠ” í•´ìƒë„ ì§€ì •
    fps = 2  # ì˜ìƒ ì €ì¥ìš© í”„ë ˆì„ ì†ë„ (ì˜ˆ: ì´ˆë‹¹ 2í”„ë ˆì„)

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))

    # âœ… í¬ì¦ˆ ë°ì´í„°ì— ìˆëŠ” ëª¨ë“  frame_id ê¸°ì¤€
    frame_ids = sorted(set(map(int, user_pose_dict.keys())) | set(map(int, ref_pose_dict.keys())))

    for frame_id in frame_ids:
        vis = np.ones((h, w, 3), dtype=np.uint8) * 255  # í° ë°°ê²½

        user_pose = normalize_keys(user_pose_dict.get(str(frame_id), {}))
        ref_pose = normalize_keys(ref_pose_dict.get(str(frame_id), {}))

        draw_pose(vis, user_pose, (255, 0, 0), w, h)
        draw_pose(vis, ref_pose, (0, 255, 0), w, h)

        cv2.putText(vis, f"Frame: {frame_id}", (30, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)

        cv2.imshow('Pose Only', cv2.resize(vis, None, fx=0.5, fy=0.5))
        if cv2.waitKey(500) & 0xFF == 27:
            break

        out.write(vis)

    out.release()
    cv2.destroyAllWindows()
    print(f"[âœ…] ì €ì¥ ì™„ë£Œ: {output_path}")




# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open("D:\\LearningPython\\capston\\originalKeypoints\\test_user_pose_normalized.json") as f:
    user_pose_dict = json.load(f)

with open("D:\\LearningPython\\capston\\originalKeypoints\\test_ref_pose_normalized.json") as f:
    ref_pose_dict = json.load(f)

draw_skeletons_without_video(
    user_pose_dict=user_pose_dict,
    ref_pose_dict=ref_pose_dict,
    output_path="D:\\LearningPython\\capston\\outputVideos\\pose_only_overlay.mp4"
)
